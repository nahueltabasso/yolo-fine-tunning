= **YOLO Fine-Tunning and Optimization for Credit Card Detections**

This repository is intended to host the project of Fine-Tunning of **YOLOv10** model. It used **FiftyOne** to manage the annotations and datasets and are integrated with tools such as **CVAT** for the correction of annotations.

This research project is divided into three parts:

1- **YOLOv10** Fine-Tunning to detect credit cards in images.

2- **YOLOv10** Fine-Tunning for the detection of the elements of a credit card (Card Number, Cardholder, Expiry Date, Payment Network).

3- **YOLOv10** Fine-Tunning for the classification of the card payment network.

**Note:** to see the step-by-step process go to link:https://github.com/nahueltabasso/yolo-fine-tunning/blob/main/src/demo/demo.ipynb[Demo]

The main flux of this project includes:

* Automatic labeling of the dataset using **GroundingDINO**
* Upload datasets to **FiftyOne**
* Export datasets to **CVAT** and fix wrong labels
* Export datasets from **FiftyOne** with a YOLO format
* Fine-Tunning of YOLO models using a custom dataset

== **Technologies**
* Python 3.9
* PyTorch
* Docker
* Ultralytics (YOLO)
* GroundingDINO
* FiftyOne
* CVAT

== **Requirements**

* Python 3.9.6 or higher
* PyTorch 2.4
* Ultralytics 8.2.72
* OpenCV 4.10
* Numpy 1.26
* Dependecies specified in Pipfile
* Docker 20.10.21 or higher

== **Getting Started**

This project uses `pipenv` to manage a python virtual environment and dependencies, or uses `docker` for this task. To set up this environment, follow the steps below 

[source,bash]
git clone https://github.com/nahueltabasso/yolo-fine-tunning.git
cd yolo-fine-tunning

First of all, it is needed to create some directories and download some heights for our models

**Directory and weight for GroundingDINO**
[source,bash]
mkdir weights
cd weights
wget -q https://github.com/IDEA-Research/GroundingDINO/releases/download/v0.1.0-alpha/groundingdino_swint_ogc.pth

You can set up the development environment for this project in two ways: using `Docker`
or using a Python Virtual Environment with `pipenv`. 

**Directory and weight for YOLO**
[source,bash]
mkdir models
cd models
wget -q https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov10n.pt

Or you can download it with this link link:https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov10n.pt[YOLOv10 Nano]

**NOTE:** Also, it is needed to configure some enviroment variables:
[source,bash]
BASE_INPUT_DIR_IMAGES=<value>
BASE_OUTPUT_DIR_IMAGES=<value>
BASE_OUTPUT_DIR_ANN=<value>
DS_BASE_DIR_PATH=<value>
MODEL_WEIGHT_PATH=<value>
BASE_TEST_IMAGE_DIR=<value>
BASE_TEST_VIDEO_DIR=<value>

=== **Set up using pipenv**

If you do not have `pipenv` installed, run the follow command:
[source,bash]
pip install pipenv

Create a virtual environment, active the new environment and install dependencies
[source,bash]
pipenv --python 3.9.6
pipenv shell
pipenv install
pipenv run pip install git+https://github.com/IDEA-Research/GroundingDINO.git@df5b48a3efbaa64288d8d0ad09b748ac86f22671
python setup.py

=== **Set up using docker**

First, it is needed to build the docker image with `docker-compose`, after this put the image up to create a container with all the necessary to execute the different scripts.
[source,bash]
docker-compose build
docker-compose up -d

=== **Using of scripts**

==== **Automate annotations for a dataset**
[source,bash]
python src/process/generateDataset_cardDetection.py 

==== **Load dataset to FiftyOne**
[source,bash]
python src/fiftyone/fo_load_ds.py --name <dataset_name>

==== **Load samples to CVAT**
[source,bash]
python src/fiftyone/fo_load_ds_cvat.py --name <dataset_name> --anno_key <anno_key> --project_name <cvat_project_name>

==== **Load annotations from CVAT to FiftyOne**
First it is needed to define some enviroment variables
[source,bash]
export FIFTYONE_CVAT_USERNAME="username" && export FIFTYONE_CVAT_PASSWORD="********" && export FIFTYONE_CVAT_URL="https://cvat.com"

[source,bash]
python src/fiftyone/fo_load_annotations.py --name <dataset_name> --anno_key <anno_key>

==== **Export dataset YOLO format**
[source,bash]
python src/fiftyone/fo_export_ds.py --name <dataset_name> --export_dir <path_to_export_dataset>

==== **Train a YOLO Model**
[source,bash]
python src/fine-tunning/train.py --model <path_to_your_model> --data <path_to_dataset.yaml>

==== **Test your model**
[source,bash]
python src/fine-tunning/test_model.py --model <path_to_your_model> --data <path_to_dataset.yaml>

=== **Inference on image or video**
[source,bash]
python src/fine-tunning/inference_on_image.py --model <path_to_your_model> --image <path_to_your_image>
python src/fine-tunning/inference_on_video.py --model <path_to_your_model> --image <path_to_your_image>

**NOTE:** In this link you have the weights after a fine-tunning link:https://drive.google.com/file/d/1VxjmZVxBHcAtYlmpLu_SyohWW5UFVhEx/view?usp=drive_link[YOLOv10 Fine-Tunning]

**NOTE:** In the following page, there is a report about this fine-tunning link:./docs/REPORT.adoc[Report].

**NOTE:** To know more about YOLO and how to fine-tunne a YOLO model visit this page link:https://docs.ultralytics.com/es/models/yolov10/[Ultralytics YOLOv10 Docs]

== **Licence**
This project was under https://opensource.org/license/mit/[MIT LICENSE] license.

== **Contact**
If you have some question about this you can contact me to my email nahueltabasso@gmail.com
